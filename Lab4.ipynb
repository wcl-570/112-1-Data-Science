{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42t-dya0jslR"
   },
   "source": [
    "# B. Programming Exercise (30 points)\n",
    "Through this assignment, students will become familiar with basic operations using pandas.\n",
    "\n",
    "**note:**\n",
    "* You can use pipenv to install all modules you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DrRV1SrjslT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from pandas.api.types import is_string_dtype\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0g8yLwljslT"
   },
   "outputs": [],
   "source": [
    "# Read 'Pokemon.csv' file.\n",
    "df = pd.read_csv('Pokemon.csv', delimiter=',', encoding='utf-8')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDpGPFhsjslT"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Legendary']==True) & (df['Attack'] > 150)]\n",
    "\n",
    "df[df['Legendary']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Legendary']==False) & (df['Attack'] > 150)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Defense'] > 200) & (df['Attack'] < 25)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDjHxjlWjslU"
   },
   "source": [
    "### **Question 1 (10 pts)**\n",
    "\n",
    "a. How many percentage of legendary Pokemons with an `Attack` value greater than 150? (3 pts)\n",
    "\n",
    "b. Also, we want to know how many percentage of non-legendary Pokemons with an `Attack` value greater than 150? (3 pts)\n",
    "\n",
    "c. Describe what you found. (1 pts)\n",
    "\n",
    "d. With the scatter plot in *lab04.pdf*, find which pokemon is the outlier at the lower right corner. (3 pts)\n",
    "\n",
    "\n",
    "**note**\n",
    "* Write your answers in answer sheet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jFxGUCijslU"
   },
   "source": [
    "### **Question 2 (10 pts)**\n",
    "We have a DataFrame about pokemons now. We want to know the distribution of pokemon for each type.\n",
    "\n",
    "Complete the function ***pokemon_type_count()***\n",
    "\n",
    "\n",
    "**note:**\n",
    "* We only consider type1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPzKB31kjslU"
   },
   "outputs": [],
   "source": [
    "\n",
    "def pokemon_type1_count(df):\n",
    "    \"\"\"\n",
    "    compute the number of pokemons for each type1\n",
    "\n",
    "\n",
    "    Args:\n",
    "        pokemon (pd.DataFrame) : pokemon dataframe\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, int] : dictionary of pokemon types and their counts\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the number of PokÃ©mon for each 'Type 1'\n",
    "    type1_count = df['Type 1'].value_counts().to_dict()\n",
    "    \n",
    "    return type1_count\n",
    "\n",
    "    # TODO_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kww1lDU-jslV"
   },
   "outputs": [],
   "source": [
    "# This is the assistant's program for review, please do not delete.\n",
    "def test_pokemon_type(pokemon_dict):\n",
    "    \"\"\"\n",
    "    test the pokemon type dictionary\n",
    "\n",
    "    Args:\n",
    "        pokemon_dict (Dict[str, int]) : pokemon type dictionary\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    assert isinstance(pokemon_dict, dict), 'pokemon_dict should be a dictionary'\n",
    "    assert all(isinstance(key, str) for key in pokemon_dict.keys()), 'pokemon_dict keys should be strings'\n",
    "    assert all(isinstance(value, int) for value in pokemon_dict.values()), 'pokemon_dict values should be integers'\n",
    "    assert all(value > 0 for value in pokemon_dict.values()), 'pokemon_dict values should be positive integers'\n",
    "    assert pokemon_dict['Water'] == 112, 'pokemon_dict should have 112 water pokemon'\n",
    "    assert pokemon_dict['Normal'] == 98, 'pokemon_dict should have 98 normal pokemon'\n",
    "    assert sum(pokemon_dict.values()) == 800, 'pokemon_dict values should sum to 800'\n",
    "\n",
    "    print('All tests passed!')\n",
    "\n",
    "\n",
    "test_pokemon_type(pokemon_type1_count(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06pJFmaJjslV"
   },
   "source": [
    "## Question 3 (10 pts)\n",
    "\n",
    "We want to compare the attack value in each generation.\n",
    "\n",
    "Complete the function `average_attack_type()`, the input should be a pd.DataFrame and output should be a dictionary.\n",
    "\n",
    "\n",
    "**note**\n",
    "* If the pokemon has multiple types, you should consider it in both types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7TpGCQ4jslV"
   },
   "outputs": [],
   "source": [
    "def average_attack_type(df):\n",
    "    \"\"\"\n",
    "    compute the average attack for each type1\n",
    "\n",
    "\n",
    "    Args:\n",
    "        pokemon (pd.DataFrame) : pokemon dataframe\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, int] : dictionary of pokemon types and their average attack\n",
    "    \"\"\"\n",
    "    type_attacks = {}\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        for pokemon_type in [row['Type 1'], row['Type 2']]:\n",
    "            if not pd.isna(pokemon_type):\n",
    "                if pokemon_type not in type_attacks:\n",
    "                    type_attacks[pokemon_type] = []\n",
    "                type_attacks[pokemon_type].append(row['Attack'])\n",
    "    \n",
    "    average_attack_dict = {}\n",
    "    for type_name, attack_values in type_attacks.items():\n",
    "        average_attack_dict[type_name] = np.mean(attack_values)\n",
    "    \n",
    "    return average_attack_dict\n",
    "    # TODO_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5nbZ1cvjslV"
   },
   "outputs": [],
   "source": [
    "# This is the assistant's program for review, please do not delete.\n",
    "def test_average_attack_type(average_attack_type):\n",
    "    \"\"\"\n",
    "    test the average attack type dictionary\n",
    "\n",
    "    Args:\n",
    "        average_attack_type (Dict[str, int]) : average attack type dictionary\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    assert isinstance(average_attack_type, dict), 'average_attack_type should be a dictionary'\n",
    "    assert all(isinstance(key, str) for key in average_attack_type.keys()), 'average_attack_type keys should be strings'\n",
    "    assert all(isinstance(value, float) for value in average_attack_type.values()), 'average_attack_type values should be floats'\n",
    "    assert all(value > 0 for value in average_attack_type.values()), 'average_attack_type values should be positive floats'\n",
    "    assert np.allclose(average_attack_type['Water'], 73.7063492063492), 'average_attack_type should have 73.7063492063492 water pokemon'\n",
    "    assert np.allclose(average_attack_type['Grass'], 73.46315789473684), 'average_attack_type should have 73.46315789473684 grass pokemon'\n",
    "\n",
    "    print('All tests passed!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_average_attack_type(average_attack_type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Data Analysis and Visualization for Climate Change (60 points)\n",
    "In this part, you will work with a dataset GlobalLandTemperaturesByState.csv containing historical climate data for states across the world from the year 1744 to 2013. The dataset includes average temperature for various states and their respective date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 1: Data Import (6 points)**\n",
    "Use Pandas to import the climate change dataset into a DataFrame called `df_state`. Then find out all the country names from the 'Country' column and print them out. (there are a total of seven unique country names.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the climate change dataset GlobalLandTemperaturesByState.csv into a DataFrame called df_state.\n",
    "import pandas as pd\n",
    "\n",
    "df_state = pd.read_csv('GlobalLandTemperaturesByState.csv')\n",
    "#print(df_state)\n",
    "# TODO_1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pandas to find out all the country names from the 'Country' column and print them out.\n",
    "# Your output should print seven unique country names.\n",
    "\n",
    "unique_country_names = df_state['Country'].unique()\n",
    "print(unique_country_names)\n",
    "\n",
    "# TODO_1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 2: Data Cleaning (12 points, 12 points)**\n",
    "The first step in examining any dataset involves the preparation and refinement of the data. Various forms of irregularities can occur during the data collection or curation process, and it is essential to rectify these issues before conducting any analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**i.** Implement the function ***cleanse_country_data*** that does the followings:\n",
    "- Some country names include additional abbreviation, such as \"United States (US)\". Create the function to simplify these names, we should discard any additional abbreviation. In a broader sense, any country name in the format \"name1 (name2)\" should be replaced with just \"name1\".\n",
    "- The list `countries_to_remove` is provided because the data for these countries is inaccurate or incomplete.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_state\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def cleanse_country_data(df):\n",
    "    \"\"\"\n",
    "    Remove countries in the countries_to_remove list from the dataframe df_state\n",
    "    and simplify the country names that include additional abbreviation.\n",
    "\n",
    "    kwargs:\n",
    "        country_data (pd.DataFrame) : the input dataframe to preprocess\n",
    "\n",
    "    return:\n",
    "        pd.DataFrame : the preprocessed dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df['Country'] = df['Country'].str.replace(r'\\s*\\(.*\\)', '', regex=True)\n",
    "\n",
    "    countries_to_remove = ['Brazil', 'Russia']\n",
    "\n",
    "    df = df[~df['Country'].isin(countries_to_remove)]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = cleanse_country_data(df) \n",
    "\n",
    "print(df)\n",
    "    # TODO_2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the assistant's program for review, please do not delete.\n",
    "def test_preprocess_countries():\n",
    "    df_country_cleaned = cleanse_country_data(df_state.copy())\n",
    "    assert df_country_cleaned.columns.equals(df_state.columns)\n",
    "    assert df_country_cleaned.dtypes.equals(df_state.dtypes)\n",
    "    assert len(df_country_cleaned) == 29699\n",
    "    \n",
    "    unique_countries = df_country_cleaned[\"Country\"].unique()\n",
    "    assert len(unique_countries) == 5\n",
    "    assert 'United States' in unique_countries\n",
    "    assert 'Brazil' not in unique_countries\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "test_preprocess_countries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii.** Missing data can cause issues when we're analyzing the data, and the easiest way to deal with this is to delete rows that have any missing values. Create the function ***drop_missing_values*** to eliminate rows in our datasets that have missing values in any column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_values(df):\n",
    "    \"\"\"\n",
    "    Drop rows with at least one missing value from an input dataframe.\n",
    "\n",
    "    args:\n",
    "        df (pd.DataFrame) : an input dataframe\n",
    "\n",
    "    returns:\n",
    "        pd.DataFrame : a subset of df where rows with missing values in any column are removed.\n",
    "    \"\"\"\n",
    "\n",
    "# Sample DataFrame\n",
    "data = df_state\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def drop_missing_values(df):\n",
    "    # Drop rows with any missing values\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# Call the function to drop missing values\n",
    "df_cleaned = drop_missing_values(df)\n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "print(df_cleaned)\n",
    "\n",
    "# TODO_2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the assistant's program for review, please do not delete.\n",
    "df_country_filtered = drop_missing_values(df_state.copy())\n",
    "assert df_country_filtered.columns.equals(df_state.columns)\n",
    "assert df_country_filtered.dtypes.equals(df_state.dtypes)\n",
    "assert len(df_country_filtered) == 51831\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 3: Data Analysis (12 points)**\n",
    "\n",
    "We can get an overview of our dataset by examining summary statistics. To do this, we will use\n",
    "Pandas to load DataFrame and then display key statistics such as\n",
    "the minimum value, maximum value, average (mean), and standard deviation of the\n",
    " \"AverageTemperature\" column in `df_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the key statistics such as the minimum value, maximum value, average (mean),and standard deviation of the \"AverageTemperature\" column in df_state.\n",
    "# Use the describe() method to display summary statistics\n",
    "summary_statistics = df_state['AverageTemperature'].describe()\n",
    "\n",
    "# Display the summary statistics\n",
    "print(summary_statistics)\n",
    "# TODO_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 4: Outlier Detection (12 points, 6 points)**\n",
    "\n",
    "We can identify outliers using the Interquartile Range (IQR) rule: a data point is considered outlier if it is at least 1.5 interquartile ranges below the first quartile (Q1), or at least 1.5 interquartile ranges above the third quartile (Q3), i.e.,\n",
    "\n",
    "### $$\\text{outlier} \\le Q1 - 1.5 \\times IQR \\text{  OR  } \\text{outlier} \\ge Q3 + 1.5 \\times IQR.$$\n",
    "\n",
    " Introduction of IQR: https://en.wikipedia.org/wiki/Interquartile_range\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function named ***remove_outliers***. This function will be responsible for removing rows from a DataFrame where the values in a specified column are identified as outliers based on the IQR rule.\n",
    "\n",
    "After creating the function, apply it to the \"AverageTemperature\" column in our DataFrame `df_state` store the result in a new DataFrame called `df_removed`. Next, compare the minimum value, maximum value, average (mean), and standard deviation of `df_removed` to those of `df_state` where the ***remove_outliers*** function was not used.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, col):\n",
    "    \"\"\"\n",
    "    Remove any row whose data at a given column is considered outlier according to the IQR rule.\n",
    "\n",
    "        args:\n",
    "        df (pd.DataFrame) : an input dataframe where outlier rows should be removed\n",
    "        col (str) : the column name to check for outlier\n",
    "\n",
    "    return:\n",
    "        pd.DataFrame : a subset of the input dataframe after outlier rows are removed\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO_4\n",
    "    # Calculate Q1 and Q3\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "\n",
    "    # Calculate IQR\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the lower and upper bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Remove outliers\n",
    "    df_removed = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    \n",
    "    return df_removed\n",
    "\n",
    "\n",
    "# Apply remove_outliers to the \"AverageTemperature\" column\n",
    "df_removed = remove_outliers(df_state, \"AverageTemperature\")\n",
    "\n",
    "# Compare statistics to the original data\n",
    "original_mean = df_state[\"AverageTemperature\"].mean()\n",
    "original_min = df_state[\"AverageTemperature\"].min()\n",
    "original_max = df_state[\"AverageTemperature\"].max()\n",
    "original_std = df_state[\"AverageTemperature\"].std()\n",
    "\n",
    "removed_mean = df_removed[\"AverageTemperature\"].mean()\n",
    "removed_min = df_removed[\"AverageTemperature\"].min()\n",
    "removed_max = df_removed[\"AverageTemperature\"].max()\n",
    "removed_std = df_removed[\"AverageTemperature\"].std()\n",
    "\n",
    "# Print the statistics for comparison\n",
    "\n",
    "print(f\"Original Data - Mean: {original_mean},Min: {original_min}, Max: {original_max},Std: {original_std}\")\n",
    "print(f\"Data after Removing Outliers - Mean: {removed_mean}, Min: {removed_min}, Max: {removed_max}, Std: {removed_std}\")\n",
    "print(df_removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the assistant's program for review, please do not delete.\n",
    "def test_remove_outliers():\n",
    "    df_country_new = remove_outliers(df_state.copy(), \"AverageTemperature\")\n",
    "    assert df_state.columns.equals(df_state.columns)\n",
    "    assert df_state.dtypes.equals(df_state.dtypes)\n",
    "    assert len(df_country_new) == 53786\n",
    "    assert abs(df_country_new[\"AverageTemperature\"].min() + 42.97) < 0.01\n",
    "    assert abs(df_country_new[\"AverageTemperature\"].max() - 32.21) < 0.01\n",
    "    assert abs(df_country_new[\"AverageTemperature\"].mean() + 3.36) < 0.01\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "test_remove_outliers()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
